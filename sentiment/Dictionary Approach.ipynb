{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82bbfba3",
   "metadata": {},
   "source": [
    "# Dictionary Approach\n",
    "\n",
    "In this notebook, we apply a dictionary-based approach to classify the sentiment of articles and evaluate its performance on the same 256 test articles used for testing the LSTM model. The dictionary used is by [Bannier, Pauls, and Walter (BPW)](https://link.springer.com/article/10.1007/s11573-018-0914-8), which is the German adaptation of the popular dictionary by [Loughran and McDonald (2011)](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6261.2010.01625.x).\n",
    "\n",
    "The main goal is to compare the performance of the LSTM model with the dictionary-based method. The BPW dictionary, specifically tailored for business communication, is known for producing sentiment indices that strongly correlate with key economic and financial variables. This makes it a suitable choice for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd818e",
   "metadata": {},
   "source": [
    "First, we load the MTI dataset, and then, using the pre-defined test indices, we filter the articles and labels to select only those belonging to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6794aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Open and read articles from the 'articles.txt' file \n",
    "with open('MediaTenor_data/articles.txt', 'r', encoding = 'utf-8') as f:\n",
    "    articles = f.read().split('\\n')  # Splitting into a list of articles\n",
    "\n",
    "# Open and read labels from the 'labels_binary.txt' file    \n",
    "with open('MediaTenor_data/labels_binary.txt', 'r', encoding = 'utf-8') as f:\n",
    "    labels = f.read().split('\\n')  # Splitting into a list of labels\n",
    "       \n",
    "# Load the test indices from the CSV file\n",
    "with open('test_indices.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    test_indices = list(map(int, next(reader))) \n",
    "\n",
    "# Filter articles and labels for the test set\n",
    "test_articles = [articles[i] for i in test_indices]\n",
    "test_labels = [labels[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb4d66",
   "metadata": {},
   "source": [
    "Next, we filter the articles to retain only the sentences that contain at least one word related to business cycle conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a3934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mokuneva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:50.345330\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "import multiprocessing as mp \n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import keep_economy_related_sentences\n",
    "\n",
    "NUM_CORE = 60 # set the number of cores to use\n",
    "\n",
    "# Set the path variable to point to the 'word_embeddings' directory\n",
    "path = os.getcwd().replace('\\\\sentiment', '') + '\\\\word_embeddings'\n",
    "\n",
    "# Load words related to 'Wirtschaft' and 'Konjunktur'\n",
    "konjunktur_words = keep_economy_related_sentences.load_words(path + '\\\\konjunktur_synonyms.txt')\n",
    "wirtschaft_words = keep_economy_related_sentences.load_words(path + '\\\\wirtschaft_synonyms.txt')\n",
    "\n",
    "# Combine the two lists\n",
    "economy_related_words = konjunktur_words + wirtschaft_words\n",
    "\n",
    "startTime = datetime.now() \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    inputs = zip(test_articles, [economy_related_words]*len(test_articles))\n",
    "    economy_related_sentences = pool.starmap(keep_economy_related_sentences.keep_economy_related_sentences, inputs) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b2e59",
   "metadata": {},
   "source": [
    "We then load the BPW dictionary from an Excel file and create two lists: one containing negative terms and another containing positive terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c2c6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbau', 'abbauen', 'abbauend', 'abbauende', 'abbauendem']\n",
      "['adäquat', 'adäquate', 'adäquatem', 'adäquaten', 'adäquater']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read an Excel file, transform an output into a list\n",
    "bpw_neg = list(pd.read_excel('BPW_Dictionary.xlsx', sheet_name='NEG_BPW', header=None).iloc[:,0]) \n",
    "bpw_pos = list(pd.read_excel('BPW_Dictionary.xlsx', sheet_name='POS_BPW', header=None).iloc[:,0])\n",
    "\n",
    "# Convert boolean value back to its intended string form\n",
    "bpw_neg = ['falsch' if word is False else word for word in bpw_neg]\n",
    "\n",
    "print(bpw_neg[:5])\n",
    "print(bpw_pos[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe20d8",
   "metadata": {},
   "source": [
    "After that, we create an array `X` that records the number of times each negative word from the BPW dictionary appears in each of the test articles.\n",
    "\n",
    "[CounVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) converts all characters to lowercase, tokenizes a text by extracting words of at least 2 letters and counts the occurence of tokens from the `vocabulary` in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dff018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10147)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate the vectorizer object\n",
    "vectorizer = CountVectorizer(analyzer = 'word', vocabulary = bpw_neg)\n",
    "\n",
    "# Fit a vectorizer to the articles and use it to transform them\n",
    "# vectorizer.fit_transform returns a sparse matrix recording the number of times each word from the vocabulary appears;\n",
    "# toarray() transforms a sparse matrix into a numpy array\n",
    "X = vectorizer.fit_transform(list(economy_related_sentences)).toarray()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164467d",
   "metadata": {},
   "source": [
    "Now, we create a DataFrame `data` where we will store the filtered article texts, along with the number of positive and negative words in each article, and the total number of words. We then calculate the number of negative words in each article using the previously created matrix and add this count as a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787dcda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame 'data' where we will store the filtered article texts,\n",
    "# along with the count of positive and negative words, and the total number of words in each article\n",
    "data = pd.DataFrame({'text': economy_related_sentences})\n",
    "\n",
    "# axis = 1: find the sum of all the values over the column axis (the number of negative words in each article)\n",
    "negative = pd.DataFrame(X).sum(axis=1)\n",
    "\n",
    "# Create a column with the count of negative words\n",
    "data['negative'] = negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78588a84",
   "metadata": {},
   "source": [
    "In a similar manner, we calculate the number of positive words in each article by fitting the vectorizer to the positive terms from the BPW dictionary. We add this count as a new column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906a5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer object\n",
    "vectorizer = CountVectorizer(analyzer = 'word', vocabulary = bpw_pos)\n",
    "\n",
    "# Fit a vectorizer to the articles and use it to transform them\n",
    "# vectorizer.fit_transform returns a sparse matrix recording the number of times each word from the vocabulary appears;\n",
    "# toarray() transforms a sparse matrix into a numpy array\n",
    "X = vectorizer.fit_transform(list(economy_related_sentences)).toarray()\n",
    "\n",
    "# axis = 1: find the sum of all the values over the column axis (the number of positive words in each article)\n",
    "positive = pd.DataFrame(X).sum(axis=1)\n",
    "\n",
    "# Create a column with the count of positive words\n",
    "data['positive'] = positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b0052",
   "metadata": {},
   "source": [
    "The final statistic required for calculating sentiment is the total number of words in each article. We use the `CountVectorizer` again to compute the word count and add this as a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da642218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer object\n",
    "vectorizer = CountVectorizer(analyzer = 'word')\n",
    "\n",
    "# Fit a vectorizer to the articles and use it to transform them.\n",
    "# vectorizer.fit_transform returns a sparse matrix recording the number of times each word from the vocabulary appears;\n",
    "# toarray() transforms a sparse matrix into a numpy array\n",
    "X = vectorizer.fit_transform(list(economy_related_sentences)).toarray()\n",
    "\n",
    "# axis = 1: find the sum of all the values over the column axis (the number of words in each article)\n",
    "word_count = X.sum(axis=1)\n",
    "\n",
    "# Create a column with the word count\n",
    "data['word_count'] = word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08031c91",
   "metadata": {},
   "source": [
    "Finally, we calculate the sentiment for each article as the proportion of positive words minus the proportion of negative words, relative to the total word count. This value is then added as a new column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b88007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentiment of each article as the propotion of positive words minus the proportion of negative words\n",
    "data['sentiment_bpw'] = (data['positive']-data['negative'])/data['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386b994",
   "metadata": {},
   "source": [
    "Since we need a binary classification for sentiment—either negative or positive/no clear tone—we transform the sentiment score into a class label. If the score is negative, the article is classified as having a negative sentiment toward business cycle conditions; otherwise, it is considered to have a positive or neutral tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e38880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment_bpw</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mehr als zwei Drittel der Inder glauben nach e...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IfD Allensbach befragt für Capital und die \"FA...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>205</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berlin/Kiel - Die deutsche Konjunktur gewinnt ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es droht nämlich eine Rezession in den USA, we...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.086207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berlin - Die deutsche Konjunktur legt eine Ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  positive  \\\n",
       "0  Mehr als zwei Drittel der Inder glauben nach e...         2         0   \n",
       "1  IfD Allensbach befragt für Capital und die \"FA...         6         7   \n",
       "2  Berlin/Kiel - Die deutsche Konjunktur gewinnt ...         0         1   \n",
       "3  Es droht nämlich eine Rezession in den USA, we...         5         0   \n",
       "4  Berlin - Die deutsche Konjunktur legt eine Ver...         1         0   \n",
       "\n",
       "   word_count  sentiment_bpw  predictions  \n",
       "0          74      -0.027027            0  \n",
       "1         205       0.004878            1  \n",
       "2          21       0.047619            1  \n",
       "3          58      -0.086207            0  \n",
       "4          42      -0.023810            0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['predictions'] = data['sentiment_bpw'].apply(lambda x: 0 if x < 0 else 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba758b88",
   "metadata": {},
   "source": [
    "To evaluate the performance of the dictionary-based approach, we first need to convert the true labels into a binary format: 0 for negative sentiment and 1 for positive/no clear tone class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b75fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert labels to binary format: 1 for 'positive' and 0 for 'negative'\n",
    "encoded_labels = np.array([1 if label == 'positive' else 0 for label in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2fb12",
   "metadata": {},
   "source": [
    "The final step is to evaluate the performance of the dictionary-based approach. We generate a classification report that includes precision, recall, F1-score, and support for each class. Additionally, we compute and display the confusion matrix to visualize how well the model performs in terms of correct and incorrect predictions.\n",
    "\n",
    "The dictionary-based approach achieves an overall accuracy of 62.9%, compared to 66.8% for the LSTM model. While the LSTM demonstrates superior performance, validating its effectiveness, the BPW dictionary still proves to be a strong benchmark, which explains its popularity. Notably, the dictionary-based method performs particularly well on negative articles, with 73% accuracy, but struggles with those that have a positive or no clear tone, where it achieves only 53% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2122c0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.73      0.66       124\n",
      "           1       0.68      0.53      0.60       132\n",
      "\n",
      "    accuracy                           0.63       256\n",
      "   macro avg       0.64      0.63      0.63       256\n",
      "weighted avg       0.64      0.63      0.63       256\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91 33]\n",
      " [62 70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Generate and print the classification report\n",
    "# This report includes precision, recall, F1-score, and support for each class\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(encoded_labels, list(data.predictions)))\n",
    "\n",
    "# Compute and display the confusion matrix\n",
    "# The matrix aligns true labels with rows and predicted labels with columns\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(encoded_labels, list(data.predictions))\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_env_gpu",
   "language": "python",
   "name": "py3_env_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
