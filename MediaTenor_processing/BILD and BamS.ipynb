{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6f7283",
   "metadata": {},
   "source": [
    "We have downloaded the full texts of articles on the topic of business cycle conditions from LexisNexis and Factiva. These articles were annotated by Media Tenor and come from several sources: Spiegel (1,020 annotations), BILD (875 annotations), Focus (730 annotations), WamS (488 annotations), Capital (411 annotations), FAS (392 annotations), BamS (176 annotations), and Manager Magazin (16 annotations).\n",
    "\n",
    "In this notebook, we focus on loading the full texts of articles from BILD and BamS related to business cycle conditions. All of these articles were available in Factiva. We downloaded the articles in RTF format, transformed them into TXT files, and then read them into a DataFrame. Our goal is to create a DataFrame containing the following information for each article: the name of the newspaper (BILD or BamS), the day, month, and year of publication, the title, the full text, and the sentiment based on Media Tenor's annotations.\n",
    "\n",
    "BILD is a popular daily newspaper with a wide circulation. BamS, or Bild am Sonntag, is its Sunday edition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c014b",
   "metadata": {},
   "source": [
    "In our first step, we convert RTF files of articles from BamS and BILD into TXT format. These articles were downloaded from Factiva. All the RTF files are stored in `MediaTenor_LexisNexis_Factiva/BamS_Konjunktur_rtf` and `MediaTenor_LexisNexis_Factiva/BILD_Konjunktur_rtf`. The converted TXT files are stored in `MediaTenor_LexisNexis_Factiva/BamS_Konjunktur_txt` and `MediaTenor_LexisNexis_Factiva/BILD_Konjunktur_txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59f9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "def convert_rtf_to_txt(input_directory, output_directory):\n",
    "    \"\"\"\n",
    "    Convert RTF files in the input directory to TXT files in the output directory.\n",
    "    Remove any temporary files starting with ~$ in the output directory.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Iterate through all RTF files in the input directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".rtf\"):\n",
    "            # Read the RTF file and convert it to plain text\n",
    "            with codecs.open(os.path.join(input_directory, filename), \"r\") as file:\n",
    "                text_rtf = rtf_to_text(file.read())\n",
    "            \n",
    "            # Replace the .rtf extension with .txt for the new file\n",
    "            new_filename = filename.replace(\".rtf\", \".txt\")\n",
    "            \n",
    "            # Write the converted text to the new TXT file\n",
    "            with codecs.open(os.path.join(output_directory, new_filename), 'w', encoding='utf-8') as new_file:\n",
    "                new_file.write(text_rtf)\n",
    "                \n",
    "    # Remove any temporary files starting with ~$\n",
    "    for filename in os.listdir(output_directory):\n",
    "        if filename.startswith(\"~$\"):\n",
    "            os.remove(os.path.join(output_directory, filename))\n",
    "\n",
    "# Define paths for BamS\n",
    "bams_rtf_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'BamS_Konjunktur_rtf')\n",
    "bams_txt_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'BamS_Konjunktur_txt')\n",
    "\n",
    "# Define paths for BILD\n",
    "bild_rtf_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'BILD_Konjunktur_rtf')\n",
    "bild_txt_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'BILD_Konjunktur_txt')\n",
    "\n",
    "# Convert RTF files to TXT for BamS\n",
    "convert_rtf_to_txt(bams_rtf_path, bams_txt_path)\n",
    "\n",
    "# Convert RTF files to TXT for BILD\n",
    "convert_rtf_to_txt(bild_rtf_path, bild_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162f0eb",
   "metadata": {},
   "source": [
    "For BamS and BILD, we had to manually review each TXT file to ensure it represented an individual article. Often, these files contained multiple articles in a single document. When this happened, we manually selected the annotated article from the compilation. During this review, we also added sentiment information from the Excel file provided by Media Tenor. We matched the downloaded articles with the sentiment based on the article's title, publication date, and source. Additionally, for some documents, we removed content found at the end of the text that was not part of the main article, such as captions for photos, editor notes, or background details.\n",
    "\n",
    "Once the TXT files were ready, we used the function `extract_article_data` to load the text of the articles along with the newspaper's name, date of publication, title, sentiment, and file name into a dictionary called `article_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b81b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_article_data\n",
    "\n",
    "# Read and extract relevant information from TXT files in BamS and BILD directories.\n",
    "article_data = extract_article_data.extract_article_data(bams_txt_path, bild_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e7239",
   "metadata": {},
   "source": [
    "Finally, we created a DataFrame from the `article_data` dictionary. This DataFrame includes columns for the newspaper's name, publication date (day, month, and year), article title, text, sentiment, and file name. Then, we sorted the DataFrame in chronological order and saved the resulting dataset to a CSV file named `bams_bild.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7937060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles from BamS: 146\n",
      "Number of articles from BILD: 564\n",
      "Total number of articles: 710\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BILD</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>Gipfeltreffen der Gefrusteten.</td>\n",
       "      <td>SPD-Kanzlerkandidat Peer Steinbrück hat miese ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Factiva-20200814-1023.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BILD</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>RÖSLER SICHER;  Konjunktur nimmt Fahrt auf</td>\n",
       "      <td>Berlin - Wirtschaftsminister Philipp Rösler (4...</td>\n",
       "      <td>1</td>\n",
       "      <td>Factiva-20200814-1021.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BamS</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>BLITZ-UMFRAGE VOR DEM PARTEITAG;  Selbst SPD -...</td>\n",
       "      <td>\"Wir sind noch nicht im Wahlkampfmodus\".  Augs...</td>\n",
       "      <td>0</td>\n",
       "      <td>Factiva-20200810-1444.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BamS</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>Wie lange wird es Opel noch geben ?</td>\n",
       "      <td>General-Motors-Chef Dan Akerson und sein neuer...</td>\n",
       "      <td>1</td>\n",
       "      <td>Factiva-20200810-1445.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BILD</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>POLITIK &amp; WIRTSCHAFT</td>\n",
       "      <td>Droht Pierer lebenslang?  Athen - Wegen der Sc...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Factiva-20200814-1021 (1).txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  journal  day  month  year  \\\n",
       "0    BILD    6      4  2013   \n",
       "1    BILD   10      4  2013   \n",
       "2    BamS   14      4  2013   \n",
       "3    BamS   14      4  2013   \n",
       "4    BILD   16      4  2013   \n",
       "\n",
       "                                               title  \\\n",
       "0                     Gipfeltreffen der Gefrusteten.   \n",
       "1         RÖSLER SICHER;  Konjunktur nimmt Fahrt auf   \n",
       "2  BLITZ-UMFRAGE VOR DEM PARTEITAG;  Selbst SPD -...   \n",
       "3                Wie lange wird es Opel noch geben ?   \n",
       "4                               POLITIK & WIRTSCHAFT   \n",
       "\n",
       "                                                text sentiment  \\\n",
       "0  SPD-Kanzlerkandidat Peer Steinbrück hat miese ...        -1   \n",
       "1  Berlin - Wirtschaftsminister Philipp Rösler (4...         1   \n",
       "2  \"Wir sind noch nicht im Wahlkampfmodus\".  Augs...         0   \n",
       "3  General-Motors-Chef Dan Akerson und sein neuer...         1   \n",
       "4  Droht Pierer lebenslang?  Athen - Wegen der Sc...        -1   \n",
       "\n",
       "                            file  \n",
       "0      Factiva-20200814-1023.txt  \n",
       "1      Factiva-20200814-1021.txt  \n",
       "2      Factiva-20200810-1444.txt  \n",
       "3      Factiva-20200810-1445.txt  \n",
       "4  Factiva-20200814-1021 (1).txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the article_data dictionary\n",
    "bams_bild = pd.DataFrame({\n",
    "    'journal': article_data['journal'],\n",
    "    'day': article_data['day'],\n",
    "    'month': article_data['month'],\n",
    "    'year': article_data['year'],\n",
    "    'title': article_data['titles'],\n",
    "    'text': article_data['texts'],\n",
    "    'sentiment': article_data['sentiment'],\n",
    "    'file': article_data['file']\n",
    "})\n",
    "\n",
    "# Map month names to numbers\n",
    "month_mapping = {\n",
    "    'Januar': 1, 'Februar': 2, 'März': 3, 'April': 4,\n",
    "    'Mai': 5, 'Juni': 6, 'Juli': 7, 'August': 8,\n",
    "    'September': 9, 'Oktober': 10, 'November': 11, 'Dezember': 12,\n",
    "    'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "    'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "    'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "}\n",
    "bams_bild['month'] = bams_bild['month'].map(month_mapping)\n",
    "\n",
    "# Convert day, month, and year to integers\n",
    "bams_bild['day'] = bams_bild['day'].astype(int)\n",
    "bams_bild['month'] = bams_bild['month'].astype(int)\n",
    "bams_bild['year'] = bams_bild['year'].astype(int)\n",
    "\n",
    "# Sort the data in chronological order\n",
    "bams_bild = bams_bild.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "\n",
    "# Drop duplicated articles, keeping the first occurrence\n",
    "# We have duplicates because we mistakenly downloaded the same article twice\n",
    "bams_bild = bams_bild.drop_duplicates(['text', 'year', 'month', 'day'], keep='first')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "bams_bild = bams_bild.reset_index(drop=True)\n",
    "\n",
    "# Print the number of articles from BamS and BILD\n",
    "num_bams_articles = len(bams_bild[bams_bild['journal'] == 'BamS'])\n",
    "num_bild_articles = len(bams_bild[bams_bild['journal'] == 'BILD'])\n",
    "total_articles = len(bams_bild)\n",
    "\n",
    "print(f\"Number of articles from BamS: {num_bams_articles}\")\n",
    "print(f\"Number of articles from BILD: {num_bild_articles}\")\n",
    "print(f\"Total number of articles: {total_articles}\")\n",
    "\n",
    "# Save to CSV file\n",
    "bams_bild.to_csv('bams_bild.csv', encoding='utf-8-sig', sep=';')\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "bams_bild.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
