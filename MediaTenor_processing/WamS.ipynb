{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5901167",
   "metadata": {},
   "source": [
    "In this notebook, we focus on loading the full texts of articles from WamS related to business cycle conditions. All of these articles were available in Factiva. We downloaded the articles in RTF format, transformed them into TXT files, and then read them into a DataFrame. Our goal is to create a DataFrame containing the following information for each article: the name of the newspaper, the day, month, and year of publication, the title, the full text, and the sentiment based on Media Tenor's annotations.\n",
    "\n",
    "Welt is a popular daily newspaper with a wide circulation. WamS, or Welt am Sonntag, is its Sunday edition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48d267",
   "metadata": {},
   "source": [
    "## Media Tenor dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0e267",
   "metadata": {},
   "source": [
    "To match the articles downloaded from Factiva and LexisNexis with their metadata from the Media Tenor dataset, we first need to load the Media Tenor dataset. We only retain articles with non-empty titles, as it is not possible to identify and download articles without titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f218877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>medium</th>\n",
       "      <th>title</th>\n",
       "      <th>topicgroup</th>\n",
       "      <th>negative</th>\n",
       "      <th>no_clear_tone</th>\n",
       "      <th>positive</th>\n",
       "      <th>Number_of_reports</th>\n",
       "      <th>AverageRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2014</td>\n",
       "      <td>201401</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Koalition</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>FAS</td>\n",
       "      <td>Habt bloß keine Angst vor China !</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Wir leben in einer Zeit der Wohlstands-Halluzi...</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.02.2015</td>\n",
       "      <td>201502</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Teheran ruft</td>\n",
       "      <td>Wettbewerbsfähigkeit/Nachfrage</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Geht es und wirklich so gut, wie es uns Merkel...</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   month medium  \\\n",
       "0  01.01.2014  201401   WamS   \n",
       "1  01.01.2017  201701    FAS   \n",
       "2  01.01.2017  201701   BamS   \n",
       "3  01.02.2015  201502   WamS   \n",
       "4  01.01.2017  201701   BamS   \n",
       "\n",
       "                                               title  \\\n",
       "0                                          Koalition   \n",
       "1                  Habt bloß keine Angst vor China !   \n",
       "2  Wir leben in einer Zeit der Wohlstands-Halluzi...   \n",
       "3                                       Teheran ruft   \n",
       "4  Geht es und wirklich so gut, wie es uns Merkel...   \n",
       "\n",
       "                       topicgroup  negative  no_clear_tone  positive  \\\n",
       "0                      Konjunktur         0              1         0   \n",
       "1       Internationale Wirtschaft         0              0         1   \n",
       "2                      Konjunktur         0              0         1   \n",
       "3  Wettbewerbsfähigkeit/Nachfrage         1              3         0   \n",
       "4       Internationale Wirtschaft         0              1         0   \n",
       "\n",
       "   Number_of_reports AverageRating  \n",
       "0                  1             0  \n",
       "1                  1           100  \n",
       "2                  1           100  \n",
       "3                  4           -25  \n",
       "4                  1             0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset acquired from Media Tenor\n",
    "sentiment_data = pd.read_csv('Daten_Wirtschaftliche_Lage.csv', encoding='utf-8', sep=';')\n",
    "\n",
    "# Filter out rows with empty titles, as we cannot identify and download the articles without titles\n",
    "sentiment_data = sentiment_data[sentiment_data['title'].notnull()]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee24bb",
   "metadata": {},
   "source": [
    "The titles in the Media Tenor dataset were manually entered, leading to potential inconsistencies in punctuation and spacing. To address this issue and ensure accurate matching with the titles of the articles we download from databases, we normalize the titles in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872a2c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>medium</th>\n",
       "      <th>title</th>\n",
       "      <th>topicgroup</th>\n",
       "      <th>negative</th>\n",
       "      <th>no_clear_tone</th>\n",
       "      <th>positive</th>\n",
       "      <th>Number_of_reports</th>\n",
       "      <th>AverageRating</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2014</td>\n",
       "      <td>201401</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Koalition</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>koalition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>FAS</td>\n",
       "      <td>Habt bloß keine Angst vor China !</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>habt bloß keine angst vor china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Wir leben in einer Zeit der Wohlstands-Halluzi...</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>wir leben in einer zeit der wohlstands halluzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.02.2015</td>\n",
       "      <td>201502</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Teheran ruft</td>\n",
       "      <td>Wettbewerbsfähigkeit/Nachfrage</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-25</td>\n",
       "      <td>teheran ruft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Geht es und wirklich so gut, wie es uns Merkel...</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>geht es und wirklich so gut wie es uns merkel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   month medium  \\\n",
       "0  01.01.2014  201401   WamS   \n",
       "1  01.01.2017  201701    FAS   \n",
       "2  01.01.2017  201701   BamS   \n",
       "3  01.02.2015  201502   WamS   \n",
       "4  01.01.2017  201701   BamS   \n",
       "\n",
       "                                               title  \\\n",
       "0                                          Koalition   \n",
       "1                  Habt bloß keine Angst vor China !   \n",
       "2  Wir leben in einer Zeit der Wohlstands-Halluzi...   \n",
       "3                                       Teheran ruft   \n",
       "4  Geht es und wirklich so gut, wie es uns Merkel...   \n",
       "\n",
       "                       topicgroup  negative  no_clear_tone  positive  \\\n",
       "0                      Konjunktur         0              1         0   \n",
       "1       Internationale Wirtschaft         0              0         1   \n",
       "2                      Konjunktur         0              0         1   \n",
       "3  Wettbewerbsfähigkeit/Nachfrage         1              3         0   \n",
       "4       Internationale Wirtschaft         0              1         0   \n",
       "\n",
       "   Number_of_reports AverageRating  \\\n",
       "0                  1             0   \n",
       "1                  1           100   \n",
       "2                  1           100   \n",
       "3                  4           -25   \n",
       "4                  1             0   \n",
       "\n",
       "                                         title_clean  \n",
       "0                                          koalition  \n",
       "1                    habt bloß keine angst vor china  \n",
       "2  wir leben in einer zeit der wohlstands halluzi...  \n",
       "3                                       teheran ruft  \n",
       "4  geht es und wirklich so gut wie es uns merkel ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Normalize class from the normalize module\n",
    "from normalize import Normalize\n",
    "\n",
    "# Initialize the Normalize class with the titles from the 'sentiment_data' DataFrame\n",
    "normalizer = Normalize(sentiment_data.title)\n",
    "\n",
    "# Apply the normalization process to the titles\n",
    "normalized_titles = normalizer.normalized()\n",
    "\n",
    "# Add the normalized titles to the sentiment_data DataFrame as a new column 'title_clean'\n",
    "sentiment_data['title_clean'] = normalized_titles\n",
    "\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094e667",
   "metadata": {},
   "source": [
    "We need to focus on annotated articles from WamS related to business cycle conditions, as these are the specific articles we downloaded from the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0adff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to include only articles from WamS\n",
    "sentiment_data = sentiment_data[sentiment_data['medium'] == 'WamS']\n",
    "\n",
    "# Reset the index of the DataFrame and remove the old index column\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "\n",
    "# Further filter the dataset to include only articles related to the business cycle conditions (Konjunktur)\n",
    "sentiment_data = sentiment_data[sentiment_data['topicgroup'] == 'Konjunktur']\n",
    "\n",
    "# Reset the index of the DataFrame again and remove the old index column\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a724a",
   "metadata": {},
   "source": [
    "We filter the Media Tenor dataset to only keep articles where there was agreement between annotators on sentiment. Articles without annotator agreement (i.e., where `sentiment` is `NaN`) are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ba692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>medium</th>\n",
       "      <th>title</th>\n",
       "      <th>topicgroup</th>\n",
       "      <th>negative</th>\n",
       "      <th>no_clear_tone</th>\n",
       "      <th>positive</th>\n",
       "      <th>Number_of_reports</th>\n",
       "      <th>AverageRating</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2014</td>\n",
       "      <td>201401</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Koalition</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>koalition</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.02.2015</td>\n",
       "      <td>201502</td>\n",
       "      <td>WamS</td>\n",
       "      <td>„Größtmöglicher Nutzen beim Kochen“</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>größtmöglicher nutzen beim kochen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.02.2015</td>\n",
       "      <td>201502</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Rebellion gegen Merkel</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>rebellion gegen merkel</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Alles wird gut</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>alles wird gut</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.03.2020</td>\n",
       "      <td>202003</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Deutschland bereitet sich auf Corona-Pandemie vor</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-100</td>\n",
       "      <td>deutschland bereitet sich auf corona pandemie vor</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   month medium  \\\n",
       "0  01.01.2014  201401   WamS   \n",
       "1  01.02.2015  201502   WamS   \n",
       "2  01.02.2015  201502   WamS   \n",
       "3  01.01.2017  201701   WamS   \n",
       "4  01.03.2020  202003   WamS   \n",
       "\n",
       "                                               title  topicgroup  negative  \\\n",
       "0                                          Koalition  Konjunktur         0   \n",
       "1                „Größtmöglicher Nutzen beim Kochen“  Konjunktur         0   \n",
       "2                             Rebellion gegen Merkel  Konjunktur         2   \n",
       "3                                     Alles wird gut  Konjunktur         0   \n",
       "4  Deutschland bereitet sich auf Corona-Pandemie vor  Konjunktur         3   \n",
       "\n",
       "   no_clear_tone  positive  Number_of_reports AverageRating  \\\n",
       "0              1         0                  1             0   \n",
       "1              1         0                  1             0   \n",
       "2              0         0                  2          -100   \n",
       "3              0         2                  2           100   \n",
       "4              0         0                  3          -100   \n",
       "\n",
       "                                         title_clean  sentiment  \n",
       "0                                          koalition        0.0  \n",
       "1                  größtmöglicher nutzen beim kochen        0.0  \n",
       "2                             rebellion gegen merkel       -1.0  \n",
       "3                                     alles wird gut        1.0  \n",
       "4  deutschland bereitet sich auf corona pandemie vor       -1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentiment import sentiment\n",
    "\n",
    "# Apply the 'sentiment' function to each row of the DataFrame and create a new 'sentiment' column\n",
    "sentiment_data['sentiment'] = sentiment_data.apply(lambda row: sentiment(row), axis=1)\n",
    "\n",
    "# Remove articles where there is no annotator agreement (i.e., sentiment is NaN)\n",
    "sentiment_data = sentiment_data[sentiment_data['sentiment'].notnull()]\n",
    "\n",
    "# Reset the index of the DataFrame again and remove the old index column\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame to verify the results\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b81472",
   "metadata": {},
   "source": [
    "## Load and Match Articles from Factiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fcf5b",
   "metadata": {},
   "source": [
    "Next, we focus on loading WamS articles downloaded from Factiva and matching them with their metadata. In our first step, we convert the RTF files into TXT format. All the RTF files are stored in `MediaTenor_LexisNexis_Factiva/WamS_Konjunktur_rtf`. The converted TXT files are stored in `MediaTenor_LexisNexis_Factiva/WamS_Konjunktur_txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1252293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Import the function for converting RTF to TXT\n",
    "from convert_rtf_to_txt import convert_rtf_to_txt\n",
    "\n",
    "# Define paths for WamS RTF and TXT directories\n",
    "wams_rtf_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'WamS_Konjunktur_rtf')\n",
    "wams_txt_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'WamS_Konjunktur_txt')\n",
    "\n",
    "# Convert RTF files to TXT format for WamS\n",
    "convert_rtf_to_txt(wams_rtf_path, wams_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754d3a0",
   "metadata": {},
   "source": [
    "As soon as the RTF files were transformed into TXT format, we made a few changes to the TXT files. Specifically, we corrected several titles to ensure accurate spelling and punctuation, which is important for matching them with the metadata from the Media Tenor dataset. For example, a title \"Wer **kann ' s** besser\" was corrected to \"Wer **kann's** besser\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f347303",
   "metadata": {},
   "source": [
    "Once the TXT files were ready, we used the function `extract_article_data_wams` to load the text of the articles along with the journal's name, date of publication, title, and file name into a dictionary called `article_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9836685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_article_data_wams\n",
    "\n",
    "# Read and extract relevant information from TXT files in WamS directory.\n",
    "article_data = extract_article_data_wams.extract_article_data_wams(wams_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514c10f",
   "metadata": {},
   "source": [
    "We use the `article_data` dictionary to create a DataFrame `wams` that includes columns for the journal's name, publication date (day, month, and year), article title, text, and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2acbd056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WamS</td>\n",
       "      <td>3</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Regierung kritisiert Gerichte für Urteile gege...</td>\n",
       "      <td>Kanzleramtschef Braun beklagt \"Herausforderung...</td>\n",
       "      <td>Factiva-20200813-1103.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WamS</td>\n",
       "      <td>3</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Was war denn das jetzt ?</td>\n",
       "      <td>Zu den Dingen, die es vor der Corona-Epidemie ...</td>\n",
       "      <td>Factiva-20200813-1105.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WamS</td>\n",
       "      <td>3</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>\" Wir können stolz sein \"</td>\n",
       "      <td>Kanzleramtschef Helge Braun (CDU) verteidigt d...</td>\n",
       "      <td>Factiva-20200813-1105_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WamS</td>\n",
       "      <td>3</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Krise mit Ansage</td>\n",
       "      <td>PiS-Chef Kaczynski möchte trotz Lockdown eine ...</td>\n",
       "      <td>Factiva-20200813-1107.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WamS</td>\n",
       "      <td>3</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Die neuen Leiden der Generation Z</td>\n",
       "      <td>Wer in jungen Jahren eine schwere Rezession mi...</td>\n",
       "      <td>Factiva-20200813-1108.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  journal day month  year                                              title  \\\n",
       "0    WamS   3   Mai  2020  Regierung kritisiert Gerichte für Urteile gege...   \n",
       "1    WamS   3   Mai  2020                           Was war denn das jetzt ?   \n",
       "2    WamS   3   Mai  2020                          \" Wir können stolz sein \"   \n",
       "3    WamS   3   Mai  2020                                   Krise mit Ansage   \n",
       "4    WamS   3   Mai  2020                  Die neuen Leiden der Generation Z   \n",
       "\n",
       "                                                text  \\\n",
       "0  Kanzleramtschef Braun beklagt \"Herausforderung...   \n",
       "1  Zu den Dingen, die es vor der Corona-Epidemie ...   \n",
       "2  Kanzleramtschef Helge Braun (CDU) verteidigt d...   \n",
       "3  PiS-Chef Kaczynski möchte trotz Lockdown eine ...   \n",
       "4  Wer in jungen Jahren eine schwere Rezession mi...   \n",
       "\n",
       "                          file  \n",
       "0    Factiva-20200813-1103.txt  \n",
       "1    Factiva-20200813-1105.txt  \n",
       "2  Factiva-20200813-1105_1.txt  \n",
       "3    Factiva-20200813-1107.txt  \n",
       "4    Factiva-20200813-1108.txt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "wams = pd.DataFrame({\n",
    "    'journal': article_data['journal'],\n",
    "    'day': article_data['day'],\n",
    "    'month': article_data['month'],\n",
    "    'year': article_data['year'],\n",
    "    'title': article_data['title'],\n",
    "    'text': article_data['text'],\n",
    "    'file': article_data['file']\n",
    "})\n",
    "\n",
    "wams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b6dff",
   "metadata": {},
   "source": [
    "To match the full texts of the loaded articles with their sentiment annotations from the Media Tenor dataset, we follow several key steps. First, we create a date in the same format as in the `sentiment_data` DataFrame. Next, we normalize the titles to ensure accurate matching. We also remove any duplicate articles that were mistakenly downloaded twice. After pre-processing, we merge the articles loaded from Factiva with their sentiment annotations from the Media Tenor dataset. We then sort the final DataFrame `data_match` in chronological order and retain only the relevant columns. Through this process, we successfully matched **468** WamS articles from Factiva with their sentiment annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f183f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>file</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WamS</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>Die nächste allgemeine Verunsicherung</td>\n",
       "      <td>Deutschlands führende Ökonomen senken ihre Wac...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Factiva-20200817-1247.txt</td>\n",
       "      <td>die nächste allgemeine verunsicherung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WamS</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>Ist der Euro jetzt gerettet ?</td>\n",
       "      <td>Nach dem Urteil des Bundesverfassungsgerichts ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Factiva-20200817-1244.txt</td>\n",
       "      <td>ist der euro jetzt gerettet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WamS</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>So stark ist Deutschland wirklich</td>\n",
       "      <td>Eine noch unveröffentlichte Studie zeigt: Der ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Factiva-20200817-1243.txt</td>\n",
       "      <td>so stark ist deutschland wirklich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WamS</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>Industrie :  Wachstum hält trotz Krise an</td>\n",
       "      <td>Trotz der Belastungen durch die Euro-Krise ble...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Factiva-20200817-1243_1.txt</td>\n",
       "      <td>industrie wachstum hält trotz krise an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WamS</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2012</td>\n",
       "      <td>\" Eine wahre Explosion der Kreativität \"</td>\n",
       "      <td>Der Chef der Werbeagentur Saatchi &amp; Saatchi, K...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Factiva-20200817-1240_1.txt</td>\n",
       "      <td>eine wahre explosion der kreativität</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  journal  day  month  year                                      title  \\\n",
       "0    WamS    8      7  2012      Die nächste allgemeine Verunsicherung   \n",
       "1    WamS   16      9  2012              Ist der Euro jetzt gerettet ?   \n",
       "2    WamS   22     10  2012          So stark ist Deutschland wirklich   \n",
       "3    WamS   28     10  2012  Industrie :  Wachstum hält trotz Krise an   \n",
       "4    WamS   11     11  2012   \" Eine wahre Explosion der Kreativität \"   \n",
       "\n",
       "                                                text  sentiment  \\\n",
       "0  Deutschlands führende Ökonomen senken ihre Wac...       -1.0   \n",
       "1  Nach dem Urteil des Bundesverfassungsgerichts ...        1.0   \n",
       "2  Eine noch unveröffentlichte Studie zeigt: Der ...       -1.0   \n",
       "3  Trotz der Belastungen durch die Euro-Krise ble...        1.0   \n",
       "4  Der Chef der Werbeagentur Saatchi & Saatchi, K...       -1.0   \n",
       "\n",
       "                          file                             title_clean  \n",
       "0    Factiva-20200817-1247.txt   die nächste allgemeine verunsicherung  \n",
       "1    Factiva-20200817-1244.txt             ist der euro jetzt gerettet  \n",
       "2    Factiva-20200817-1243.txt       so stark ist deutschland wirklich  \n",
       "3  Factiva-20200817-1243_1.txt  industrie wachstum hält trotz krise an  \n",
       "4  Factiva-20200817-1240_1.txt    eine wahre explosion der kreativität  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary to transform month name into month number\n",
    "name_to_number = {\n",
    "    u'Januar': '01', u'Februar': '02', u'M\\xe4rz': '03', u'April': '04', u'Mai': '05',\n",
    "    u'Juni': '06', u'Juli': '07', u'August': '08', u'September': '09', u'Oktober': '10',\n",
    "    u'November': '11', u'Dezember': '12'\n",
    "}\n",
    "\n",
    "# Transform month names into month numbers\n",
    "wams['month_num'] = wams['month'].map(name_to_number)\n",
    "\n",
    "# Create dictionary to transform single-digit day numbers\n",
    "day_transform = {u'1': '01', u'2': '02', u'3': '03', u'4': '04', u'5': '05', u'6': '06', u'7': '07', u'8': '08', u'9': '09'}\n",
    "\n",
    "# Transform single-digit day numbers into two-digit format\n",
    "wams['day'] = wams['day'].map(lambda d: day_transform.get(d, d))\n",
    "\n",
    "# Combine day, month, and year into a date string\n",
    "wams['date'] = wams.apply(lambda row: f\"{row['day']}.{row['month_num']}.{row['year']}\", axis=1)\n",
    "\n",
    "# Drop duplicated articles, keeping the first occurrence\n",
    "# We have duplicates because we mistakenly downloaded the same article twice\n",
    "wams = wams.drop_duplicates(['text', 'year', 'month', 'day'], keep='first')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "wams = wams.reset_index(drop=True)\n",
    "\n",
    "# Initialize the Normalize class with the titles from the 'wams' DataFrame\n",
    "normalizer = Normalize(wams.title)\n",
    "\n",
    "# Apply the normalization process to the titles\n",
    "normalized_titles = normalizer.normalized()\n",
    "\n",
    "# Add the normalized titles to the 'wams' DataFrame as a new column 'title_clean'\n",
    "wams['title_clean'] = normalized_titles\n",
    "\n",
    "# Merge with sentiment_data on title_clean and date\n",
    "data_match = pd.merge(sentiment_data, wams, how='inner', on=['title_clean', 'date'])\n",
    "\n",
    "# Rename the 'month_num' column to 'month'\n",
    "data_match = data_match.rename(columns={'month_num': 'month'})\n",
    "\n",
    "# Rename the 'year_y' column to 'year'\n",
    "data_match = data_match.rename(columns={'year_y': 'year'})\n",
    "\n",
    "# Convert year, month, and day to integers\n",
    "data_match['year'] = data_match['year'].astype(int)\n",
    "data_match['month'] = data_match['month'].astype(int)\n",
    "data_match['day'] = data_match['day'].astype(int)\n",
    "\n",
    "# Sort the data in chronological order\n",
    "data_match = data_match.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "data_match = data_match.reset_index(drop=True)\n",
    "\n",
    "# Rename the 'title_y' column to 'title' to reflect the title from the Factiva dataset\n",
    "data_match = data_match.rename(columns={'title_y': 'title'})\n",
    "\n",
    "# Select only the required columns\n",
    "data_match = data_match[['journal', 'day', 'month', 'year', 'title', 'text', 'sentiment', 'file', 'title_clean']]\n",
    "\n",
    "# Print the number of articles\n",
    "num_articles = len(data_match)\n",
    "\n",
    "print(f\"Number of articles: {num_articles}\")\n",
    "\n",
    "# Display the first few rows of the final matched dataset\n",
    "data_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92634a",
   "metadata": {},
   "source": [
    "As the final step, the DataFrame `data_match` is saved as a CSV file named `wams.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f355c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'title_clean' column as it is no longer needed\n",
    "data_match = data_match.drop(columns=['title_clean'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "data_match.to_csv('wams.csv', encoding='utf-8-sig', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
