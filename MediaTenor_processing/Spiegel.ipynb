{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we perform the following steps:\n",
    "\n",
    "1. **Match Articles from Spiegel's website**: \n",
    "   - We start by matching 505 articles scraped from Spiegel's website in the notebook **Web scraping from Spiegel.ipynb** with their metadata from the dataset acquired from Media Tenor, including their sentiment annotations.\n",
    "   \n",
    "2. **Identify and Download Missing Articles**:\n",
    "   - We identify 100 articles published between 2011-2016 that were annotated by Media Tenor but were not available online and could only be found in the print version of the journal. We attempted to download them from Factiva and LexisNexis depending on their availability.\n",
    "\n",
    "3. **Load and Match Articles from Factiva**: \n",
    "   - We begin by downloading 443 RTF files of Spiegel articles from Factiva. These RTF files are then converted to TXT format. After the conversion, we load the articles from the TXT files and match them with their metadata.\n",
    "\n",
    "4. **Load and Match Articles from LexisNexis**: \n",
    "   - Similarly, we download 72 RTF files of Spiegel articles from LexisNexis. These RTF files are converted to TXT format, and the articles are then loaded and matched with their sentiment annotations.\n",
    "\n",
    "5. **Combine All Articles**: \n",
    "   - Finally, we combine all these articles into one dataset and save it as a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media Tenor dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the articles scraped from Spiegel's website or downloaded from Factiva and LexisNexis with their metadata from the Media Tenor dataset, we first need to load the Media Tenor dataset. We only retain articles with non-empty titles, as it is not possible to identify and download articles without titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>medium</th>\n",
       "      <th>title</th>\n",
       "      <th>topicgroup</th>\n",
       "      <th>negative</th>\n",
       "      <th>no_clear_tone</th>\n",
       "      <th>positive</th>\n",
       "      <th>Number_of_reports</th>\n",
       "      <th>AverageRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2014</td>\n",
       "      <td>201401</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Koalition</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>FAS</td>\n",
       "      <td>Habt bloß keine Angst vor China !</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Wir leben in einer Zeit der Wohlstands-Halluzi...</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.02.2015</td>\n",
       "      <td>201502</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Teheran ruft</td>\n",
       "      <td>Wettbewerbsfähigkeit/Nachfrage</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Geht es und wirklich so gut, wie es uns Merkel...</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   month medium  \\\n",
       "0  01.01.2014  201401   WamS   \n",
       "1  01.01.2017  201701    FAS   \n",
       "2  01.01.2017  201701   BamS   \n",
       "3  01.02.2015  201502   WamS   \n",
       "4  01.01.2017  201701   BamS   \n",
       "\n",
       "                                               title  \\\n",
       "0                                          Koalition   \n",
       "1                  Habt bloß keine Angst vor China !   \n",
       "2  Wir leben in einer Zeit der Wohlstands-Halluzi...   \n",
       "3                                       Teheran ruft   \n",
       "4  Geht es und wirklich so gut, wie es uns Merkel...   \n",
       "\n",
       "                       topicgroup  negative  no_clear_tone  positive  \\\n",
       "0                      Konjunktur         0              1         0   \n",
       "1       Internationale Wirtschaft         0              0         1   \n",
       "2                      Konjunktur         0              0         1   \n",
       "3  Wettbewerbsfähigkeit/Nachfrage         1              3         0   \n",
       "4       Internationale Wirtschaft         0              1         0   \n",
       "\n",
       "   Number_of_reports AverageRating  \n",
       "0                  1             0  \n",
       "1                  1           100  \n",
       "2                  1           100  \n",
       "3                  4           -25  \n",
       "4                  1             0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset acquired from Media Tenor\n",
    "sentiment_data = pd.read_csv('Daten_Wirtschaftliche_Lage.csv', encoding='utf-8', sep=';')\n",
    "\n",
    "# Filter out rows with empty titles, as we cannot identify and download the articles without titles\n",
    "sentiment_data = sentiment_data[sentiment_data['title'].notnull()]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The titles in the Media Tenor dataset were manually entered, leading to potential inconsistencies in punctuation and spacing. To address this issue and ensure accurate matching with the titles of the articles we scrape from the website or download from databases, we normalize the titles in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>medium</th>\n",
       "      <th>title</th>\n",
       "      <th>topicgroup</th>\n",
       "      <th>negative</th>\n",
       "      <th>no_clear_tone</th>\n",
       "      <th>positive</th>\n",
       "      <th>Number_of_reports</th>\n",
       "      <th>AverageRating</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2014</td>\n",
       "      <td>201401</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Koalition</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>koalition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>FAS</td>\n",
       "      <td>Habt bloß keine Angst vor China !</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>habt bloß keine angst vor china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Wir leben in einer Zeit der Wohlstands-Halluzi...</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>wir leben in einer zeit der wohlstands halluzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.02.2015</td>\n",
       "      <td>201502</td>\n",
       "      <td>WamS</td>\n",
       "      <td>Teheran ruft</td>\n",
       "      <td>Wettbewerbsfähigkeit/Nachfrage</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-25</td>\n",
       "      <td>teheran ruft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2017</td>\n",
       "      <td>201701</td>\n",
       "      <td>BamS</td>\n",
       "      <td>Geht es und wirklich so gut, wie es uns Merkel...</td>\n",
       "      <td>Internationale Wirtschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>geht es und wirklich so gut wie es uns merkel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   month medium  \\\n",
       "0  01.01.2014  201401   WamS   \n",
       "1  01.01.2017  201701    FAS   \n",
       "2  01.01.2017  201701   BamS   \n",
       "3  01.02.2015  201502   WamS   \n",
       "4  01.01.2017  201701   BamS   \n",
       "\n",
       "                                               title  \\\n",
       "0                                          Koalition   \n",
       "1                  Habt bloß keine Angst vor China !   \n",
       "2  Wir leben in einer Zeit der Wohlstands-Halluzi...   \n",
       "3                                       Teheran ruft   \n",
       "4  Geht es und wirklich so gut, wie es uns Merkel...   \n",
       "\n",
       "                       topicgroup  negative  no_clear_tone  positive  \\\n",
       "0                      Konjunktur         0              1         0   \n",
       "1       Internationale Wirtschaft         0              0         1   \n",
       "2                      Konjunktur         0              0         1   \n",
       "3  Wettbewerbsfähigkeit/Nachfrage         1              3         0   \n",
       "4       Internationale Wirtschaft         0              1         0   \n",
       "\n",
       "   Number_of_reports AverageRating  \\\n",
       "0                  1             0   \n",
       "1                  1           100   \n",
       "2                  1           100   \n",
       "3                  4           -25   \n",
       "4                  1             0   \n",
       "\n",
       "                                         title_clean  \n",
       "0                                          koalition  \n",
       "1                    habt bloß keine angst vor china  \n",
       "2  wir leben in einer zeit der wohlstands halluzi...  \n",
       "3                                       teheran ruft  \n",
       "4  geht es und wirklich so gut wie es uns merkel ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Normalize class from the normalize module\n",
    "from normalize import Normalize\n",
    "\n",
    "# Initialize the Normalize class with the titles from the sentiment_data DataFrame\n",
    "normalizer = Normalize(sentiment_data.title)\n",
    "\n",
    "# Apply the normalization process to the titles\n",
    "normalized_titles = normalizer.normalized()\n",
    "\n",
    "# Add the normalized titles to the sentiment_data DataFrame as a new column 'title_clean'\n",
    "sentiment_data['title_clean'] = normalized_titles\n",
    "\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to focus on annotated articles from Spiegel related to business cycle conditions, as these are the specific articles we scraped from the website or downloaded from the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to include only articles from Spiegel\n",
    "sentiment_data = sentiment_data[sentiment_data['medium'] == 'Spiegel']\n",
    "\n",
    "# Reset the index of the DataFrame and remove the old index column\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "\n",
    "# Further filter the dataset to include only articles related to the business cycle conditions (Konjunktur)\n",
    "sentiment_data = sentiment_data[sentiment_data['topicgroup'] == 'Konjunktur']\n",
    "\n",
    "# Reset the index of the DataFrame again and remove the old index column\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the Media Tenor dataset to only keep articles where there was agreement between annotators on sentiment. Articles without annotator agreement (i.e., where `sentiment` is `NaN`) are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>medium</th>\n",
       "      <th>title</th>\n",
       "      <th>topicgroup</th>\n",
       "      <th>negative</th>\n",
       "      <th>no_clear_tone</th>\n",
       "      <th>positive</th>\n",
       "      <th>Number_of_reports</th>\n",
       "      <th>AverageRating</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.02.2020</td>\n",
       "      <td>202002</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Keim der Angst</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-33,33</td>\n",
       "      <td>keim der angst</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.02.2020</td>\n",
       "      <td>202002</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>»Du musst die Gesellschaft verändern wollen«</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>du musst die gesellschaft verändern wollen</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.04.2017</td>\n",
       "      <td>201704</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Eine Stunde Applaus. Und dann?</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>eine stunde applaus und dann</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.08.2015</td>\n",
       "      <td>201508</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Chinesische Heuschrecke</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>chinesische heuschrecke</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.07.2013</td>\n",
       "      <td>201307</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Spirale nach unten</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>spirale nach unten</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   month   medium                                         title  \\\n",
       "0  01.02.2020  202002  Spiegel                                Keim der Angst   \n",
       "1  01.02.2020  202002  Spiegel  »Du musst die Gesellschaft verändern wollen«   \n",
       "2  01.04.2017  201704  Spiegel                Eine Stunde Applaus. Und dann?   \n",
       "3  01.08.2015  201508  Spiegel                       Chinesische Heuschrecke   \n",
       "4  01.07.2013  201307  Spiegel                            Spirale nach unten   \n",
       "\n",
       "   topicgroup  negative  no_clear_tone  positive  Number_of_reports  \\\n",
       "0  Konjunktur         1              2         0                  3   \n",
       "1  Konjunktur         1              0         0                  1   \n",
       "2  Konjunktur         0              1         0                  1   \n",
       "3  Konjunktur         1              0         0                  1   \n",
       "4  Konjunktur         1              0         0                  1   \n",
       "\n",
       "  AverageRating                                 title_clean  sentiment  \n",
       "0        -33,33                              keim der angst        0.0  \n",
       "1          -100  du musst die gesellschaft verändern wollen       -1.0  \n",
       "2             0                eine stunde applaus und dann        0.0  \n",
       "3          -100                     chinesische heuschrecke       -1.0  \n",
       "4          -100                          spirale nach unten       -1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentiment import sentiment\n",
    "\n",
    "# Apply the 'sentiment' function to each row of the DataFrame and create a new 'sentiment' column\n",
    "sentiment_data['sentiment'] = sentiment_data.apply(lambda row: sentiment(row), axis=1)\n",
    "\n",
    "# Remove articles where there is no annotator agreement (i.e., sentiment is NaN)\n",
    "sentiment_data = sentiment_data[sentiment_data['sentiment'].notnull()]\n",
    "\n",
    "# Reset the index of the DataFrame again and remove the old index column\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame to verify the results\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Articles from Spiegel's website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the articles that we scraped from Spiegel's website and saved in two files: `spiegel_2011_2015.csv` and `spiegel_2016.csv`. We combine all the articles into a single DataFrame named `spiegel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03.01.2011</td>\n",
       "      <td>Im freien Fall. Ein Aufstand der Landwirte in ...</td>\n",
       "      <td>Im freien Fall</td>\n",
       "      <td>im freien fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.01.2011</td>\n",
       "      <td>Im Niemandsland. Die Bürgersteige von Pétionvi...</td>\n",
       "      <td>Im Niemandsland</td>\n",
       "      <td>im niemandsland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.01.2011</td>\n",
       "      <td>Die Reifeprüfung. Um eine schnelle Schlagzeile...</td>\n",
       "      <td>Die Reifeprüfung</td>\n",
       "      <td>die reifeprüfung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.01.2011</td>\n",
       "      <td>Jurassic Park. Warum ein Falter 3,3 Millionen ...</td>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>jurassic park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.01.2011</td>\n",
       "      <td>Die Machtfrage. Eine Karriere im SPIEGEL zu pl...</td>\n",
       "      <td>Die Machtfrage</td>\n",
       "      <td>die machtfrage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  03.01.2011  Im freien Fall. Ein Aufstand der Landwirte in ...   \n",
       "1  10.01.2011  Im Niemandsland. Die Bürgersteige von Pétionvi...   \n",
       "2  24.01.2011  Die Reifeprüfung. Um eine schnelle Schlagzeile...   \n",
       "3  24.01.2011  Jurassic Park. Warum ein Falter 3,3 Millionen ...   \n",
       "4  31.01.2011  Die Machtfrage. Eine Karriere im SPIEGEL zu pl...   \n",
       "\n",
       "              title       title_clean  \n",
       "0    Im freien Fall    im freien fall  \n",
       "1   Im Niemandsland   im niemandsland  \n",
       "2  Die Reifeprüfung  die reifeprüfung  \n",
       "3     Jurassic Park     jurassic park  \n",
       "4    Die Machtfrage    die machtfrage  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the paths for the CSV files\n",
    "path_spiegel_2011_2015 = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'spiegel_2011_2015.csv')\n",
    "path_spiegel_2016 = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'spiegel_2016.csv')\n",
    "\n",
    "# Load the articles scraped from Spiegel's website\n",
    "spiegel_2011_2015 = pd.read_csv(path_spiegel_2011_2015, encoding='utf-8', sep=';', names=[\"date\", \"text\", \"title\", \"title_clean\"])\n",
    "spiegel_2016 = pd.read_csv(path_spiegel_2016, encoding='utf-8', sep=';', names=[\"date\", \"text\", \"title\", \"title_clean\"])\n",
    "\n",
    "# Reset the index of the DataFrames\n",
    "spiegel_2011_2015 = spiegel_2011_2015.reset_index(drop=True)\n",
    "spiegel_2016 = spiegel_2016.reset_index(drop=True)\n",
    "\n",
    "# Combine all the articles into one DataFrame\n",
    "spiegel = pd.concat([spiegel_2011_2015, spiegel_2016])\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "spiegel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge these articles with their metadata from the Media Tenor dataset. We use an inner join on the `title_clean` and `date` columns to ensure that only articles present in both datasets are included. The final merged DataFrame includes columns for the journal's name, publication date (day, month, and year), article title, text, sentiment, and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>file</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>Schockwellen aus Fernost</td>\n",
       "      <td>Schockwellen aus Fernost. Die Katastrophe in J...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>schockwellen aus fernost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>Kalter Krieg</td>\n",
       "      <td>Kalter Krieg. Sanfte Umschuldung oder Weiter-s...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>kalter krieg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>Wieder am Abgrund</td>\n",
       "      <td>Wieder am Abgrund. Die Griechen brauchen noch ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>wieder am abgrund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>Die Nicht-Regierung</td>\n",
       "      <td>Die Nicht-Regierung. Angela Merkel bekommt ihr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>die nicht regierung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>„Große Defizite“</td>\n",
       "      <td>„Große Defizite“. Bundesfinanzminister Wolfgan...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>große defizite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   journal  day  month  year                     title  \\\n",
       "0  Spiegel   21      3  2011  Schockwellen aus Fernost   \n",
       "1  Spiegel   30      5  2011              Kalter Krieg   \n",
       "2  Spiegel    6      6  2011         Wieder am Abgrund   \n",
       "3  Spiegel   27      6  2011       Die Nicht-Regierung   \n",
       "4  Spiegel    4      7  2011          „Große Defizite“   \n",
       "\n",
       "                                                text  sentiment  \\\n",
       "0  Schockwellen aus Fernost. Die Katastrophe in J...       -1.0   \n",
       "1  Kalter Krieg. Sanfte Umschuldung oder Weiter-s...       -1.0   \n",
       "2  Wieder am Abgrund. Die Griechen brauchen noch ...       -1.0   \n",
       "3  Die Nicht-Regierung. Angela Merkel bekommt ihr...        1.0   \n",
       "4  „Große Defizite“. Bundesfinanzminister Wolfgan...       -1.0   \n",
       "\n",
       "                    file               title_clean  \n",
       "0  spiegel_2011_2015.csv  schockwellen aus fernost  \n",
       "1  spiegel_2011_2015.csv              kalter krieg  \n",
       "2  spiegel_2011_2015.csv         wieder am abgrund  \n",
       "3  spiegel_2011_2015.csv       die nicht regierung  \n",
       "4  spiegel_2011_2015.csv            große defizite  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Merge articles scraped from Spiegel's website with their metadata from the Media Tenor dataset\n",
    "data_match_scraped = pd.merge(sentiment_data, spiegel, how='inner', on=['title_clean', 'date'])\n",
    "\n",
    "# Rename the 'medium' column to 'journal'\n",
    "data_match_scraped = data_match_scraped.rename(columns={'medium': 'journal'})\n",
    "\n",
    "# Split 'date' into 'day', 'month', and 'year'\n",
    "data_match_scraped['date'] = pd.to_datetime(data_match_scraped['date'], format='%d.%m.%Y')\n",
    "data_match_scraped['day'] = data_match_scraped['date'].dt.day\n",
    "data_match_scraped['month'] = data_match_scraped['date'].dt.month\n",
    "data_match_scraped['year'] = data_match_scraped['date'].dt.year\n",
    "\n",
    "# Create 'file' column that contains the name of the CSV file\n",
    "data_match_scraped['file'] = data_match_scraped['date'].apply(lambda x: 'spiegel_2011_2015.csv' if x.year <= 2015 else 'spiegel_2016.csv')\n",
    "\n",
    "# Rename the 'title_y' column to 'title' to reflect the title from the Spiegel dataset\n",
    "data_match_scraped = data_match_scraped.rename(columns={'title_y': 'title'})\n",
    "\n",
    "# Reorder columns\n",
    "columns_order = ['journal', 'day', 'month', 'year', 'title', 'text', 'sentiment', 'file', 'title_clean']\n",
    "\n",
    "# Select and reorder the columns\n",
    "data_match_scraped = data_match_scraped[columns_order]\n",
    "\n",
    "# Sort the data in chronological order\n",
    "data_match_scraped = data_match_scraped.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "data_match_scraped = data_match_scraped.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "data_match_scraped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and Download Missing Articles\n",
    "\n",
    "The following code identifies 100 articles published between 2011-2016 that were annotated by Media Tenor but were not available online and could only be found in the print version of the journal. Since we were unable to scrape these articles from Spiegel's website, we identified these missing articles and then attempted to download them from Factiva and LexisNexis depending on their availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles to download: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>medium</th>\n",
       "      <th>title</th>\n",
       "      <th>topicgroup</th>\n",
       "      <th>negative</th>\n",
       "      <th>no_clear_tone</th>\n",
       "      <th>positive</th>\n",
       "      <th>Number_of_reports</th>\n",
       "      <th>AverageRating</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>201102</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>keine 5 Zeilen</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>keine 5 zeilen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>201103</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Reaktorkatastrophe</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>reaktorkatastrophe</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-23</td>\n",
       "      <td>201104</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Geldsegen für Schäuble</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>geldsegen für schäuble</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-17</td>\n",
       "      <td>201110</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Showdown um Mitternacht</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-66,67</td>\n",
       "      <td>showdown um mitternacht</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-11-14</td>\n",
       "      <td>201111</td>\n",
       "      <td>Spiegel</td>\n",
       "      <td>Teure Riester-Pflege</td>\n",
       "      <td>Konjunktur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>teure riester pflege</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   month   medium                    title  topicgroup  negative  \\\n",
       "0 2011-02-14  201102  Spiegel           keine 5 Zeilen  Konjunktur         0   \n",
       "1 2011-03-28  201103  Spiegel       Reaktorkatastrophe  Konjunktur         1   \n",
       "2 2011-04-23  201104  Spiegel   Geldsegen für Schäuble  Konjunktur         0   \n",
       "3 2011-10-17  201110  Spiegel  Showdown um Mitternacht  Konjunktur         2   \n",
       "4 2011-11-14  201111  Spiegel     Teure Riester-Pflege  Konjunktur         0   \n",
       "\n",
       "   no_clear_tone  positive  Number_of_reports AverageRating  \\\n",
       "0              0         1                  1           100   \n",
       "1              0         0                  1          -100   \n",
       "2              0         1                  1           100   \n",
       "3              1         0                  3        -66,67   \n",
       "4              0         1                  1           100   \n",
       "\n",
       "               title_clean  sentiment  year  \n",
       "0           keine 5 zeilen        1.0  2011  \n",
       "1       reaktorkatastrophe       -1.0  2011  \n",
       "2   geldsegen für schäuble        1.0  2011  \n",
       "3  showdown um mitternacht       -1.0  2011  \n",
       "4     teure riester pflege        1.0  2011  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_year(row):\n",
    "    \n",
    "    '''A function that extracts the year from the date'''\n",
    "    \n",
    "    return row['date'].split('.')[2]\n",
    "\n",
    "# List of years to exclude\n",
    "year_exclude = [\"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "\n",
    "# Extract the year and add it as a new column in the DataFrame\n",
    "sentiment_data['year'] = sentiment_data.apply(lambda row: extract_year(row), axis=1)\n",
    "\n",
    "# Filter the DataFrame to include only articles from 2011 to 2016\n",
    "sentiment_data_2011_2016 = sentiment_data[~sentiment_data['year'].isin(year_exclude)]\n",
    "\n",
    "# Reset the index of the DataFrame and remove the old index column\n",
    "sentiment_data_2011_2016 = sentiment_data_2011_2016.reset_index(drop=True)\n",
    "\n",
    "# Identify articles that still need to be downloaded\n",
    "to_download = sentiment_data_2011_2016[~sentiment_data_2011_2016.title_clean.isin(data_match_scraped.title_clean)]\n",
    "\n",
    "# Reset the index of the DataFrame and remove the old index column\n",
    "to_download = to_download.reset_index(drop=True)\n",
    "\n",
    "# Convert the 'date' column to datetime format for accurate sorting\n",
    "to_download['date'] = pd.to_datetime(to_download['date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort 'to_download' based on 'date'\n",
    "to_download = to_download.sort_values(by='date')\n",
    "\n",
    "# Reset the index of the DataFrame and remove the old index column\n",
    "to_download = to_download.reset_index(drop=True)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "to_download.to_csv('to_download_spiegel.csv', encoding='utf-8-sig', sep=',')\n",
    "\n",
    "print(f\"Number of articles to download: {len(to_download)}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the result\n",
    "to_download.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Match Articles from Factiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we focus on loading Spiegel articles downloaded from Factiva and matching them with their metadata. In our first step, we convert the RTF files into TXT format. All the RTF files are stored in `MediaTenor_LexisNexis_Factiva/Spiegel_Konjunktur_Factiva_rtf`. The converted TXT files are stored in `MediaTenor_LexisNexis_Factiva/Spiegel_Konjunktur_Factiva_txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function for converting RTF to TXT\n",
    "from convert_rtf_to_txt import convert_rtf_to_txt\n",
    "\n",
    "# Define paths for Spiegel RTF and TXT directories\n",
    "spiegel_rtf_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'Spiegel_Konjunktur_Factiva_rtf')\n",
    "spiegel_txt_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'Spiegel_Konjunktur_Factiva_txt')\n",
    "\n",
    "# Convert RTF files to TXT format for Spiegel\n",
    "convert_rtf_to_txt(spiegel_rtf_path, spiegel_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as the RTF files were transformed into TXT format, we made a few changes to the TXT files. Specifically, we corrected several titles to ensure accurate spelling and punctuation, which is important for matching them with the metadata from the Media Tenor dataset. For example:\n",
    "- \"Corona macht **' s** nötig\" was corrected to \"Corona macht**\\'s** nötig\"\n",
    "- \"Der Spalt zwischen Befürwortern und Gegnern der **CoronaMaßnahmen** wird größer\" was corrected to \"Der Spalt zwischen Befürwortern und Gegnern der **Corona-Maßnahmen** wird größer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the TXT files were ready, we used the function `extract_article_data_spiegel_factiva` to load the text of the articles along with the journal's name, date of publication, title, and file name into a dictionary called `article_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_article_data_spiegel_factiva\n",
    "\n",
    "# Read and extract relevant information from TXT files in Spiegel directory.\n",
    "article_data = extract_article_data_spiegel_factiva.extract_article_data_spiegel_factiva(spiegel_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `article_data` dictionary to create a DataFrame `spiegel_factiva` that includes columns for the journal's name, publication date (day, month, and year), article title, text, and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>2</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>15 Milliarden Euro weniger pro Woche</td>\n",
       "      <td>McKinsey hat ausgerechnet, wie stark die Wirts...</td>\n",
       "      <td>Factiva-20200814-1107 (1).txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>2</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sonne ,  Strand und leer</td>\n",
       "      <td>Trotz Viruskrise: Die Tourismusindustrie in Sü...</td>\n",
       "      <td>Factiva-20200814-1107.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>2</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Die Wachablösung</td>\n",
       "      <td>Die gefährliche Rivalität zwischen den USA und...</td>\n",
       "      <td>Factiva-20200814-1109.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>2</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Der Corona - Graben</td>\n",
       "      <td>Der Spalt zwischen Befürwortern und Gegnern de...</td>\n",
       "      <td>Factiva-20200814-1110 (1).txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>9</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2020</td>\n",
       "      <td>Im Corona - Wunderland</td>\n",
       "      <td>Bericht aus dem Land, das im Umgang mit Corona...</td>\n",
       "      <td>Factiva-20200814-1110 (2).txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   journal day month  year                                 title  \\\n",
       "0  Spiegel   2   Mai  2020  15 Milliarden Euro weniger pro Woche   \n",
       "1  Spiegel   2   Mai  2020              Sonne ,  Strand und leer   \n",
       "2  Spiegel   2   Mai  2020                      Die Wachablösung   \n",
       "3  Spiegel   2   Mai  2020                   Der Corona - Graben   \n",
       "4  Spiegel   9   Mai  2020                Im Corona - Wunderland   \n",
       "\n",
       "                                                text  \\\n",
       "0  McKinsey hat ausgerechnet, wie stark die Wirts...   \n",
       "1  Trotz Viruskrise: Die Tourismusindustrie in Sü...   \n",
       "2  Die gefährliche Rivalität zwischen den USA und...   \n",
       "3  Der Spalt zwischen Befürwortern und Gegnern de...   \n",
       "4  Bericht aus dem Land, das im Umgang mit Corona...   \n",
       "\n",
       "                            file  \n",
       "0  Factiva-20200814-1107 (1).txt  \n",
       "1      Factiva-20200814-1107.txt  \n",
       "2      Factiva-20200814-1109.txt  \n",
       "3  Factiva-20200814-1110 (1).txt  \n",
       "4  Factiva-20200814-1110 (2).txt  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "spiegel_factiva = pd.DataFrame({\n",
    "    'journal': article_data['journal'],\n",
    "    'day': article_data['day'],\n",
    "    'month': article_data['month'],\n",
    "    'year': article_data['year'],\n",
    "    'title': article_data['title'],\n",
    "    'text': article_data['text'],\n",
    "    'file': article_data['file']\n",
    "})\n",
    "\n",
    "spiegel_factiva.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the full texts of the loaded articles with their sentiment annotations from the Media Tenor dataset, we follow several key steps. First, we create a date in the same format as in the `sentiment_data` DataFrame. Next, we normalize the titles to ensure accurate matching. We also remove any duplicate articles that were mistakenly downloaded twice. After pre-processing, we merge the articles loaded from Factiva with their sentiment annotations from the Media Tenor dataset. We then sort the final DataFrame `data_match_factiva` in chronological order and retain only the relevant columns. Through this process, we successfully matched 443 Spiegel articles from Factiva with their sentiment annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles from Factiva: 443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>file</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>Hausmitteilung</td>\n",
       "      <td>Sie sind etwa so hoch wie die Außenmauern des ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Factiva-20200827-1114.txt</td>\n",
       "      <td>hausmitteilung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>Der serbische Premier Vucic über die Flüchtlin...</td>\n",
       "      <td>Der serbische Ministerpräsident Aleksandar Vuč...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Factiva-20200827-1056.txt</td>\n",
       "      <td>der serbische premier vucic über die flüchtlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>Reisen hilft</td>\n",
       "      <td>Tourismus leistet einen Beitrag zur Wirtschaft...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Factiva-20200827-1050.txt</td>\n",
       "      <td>reisen hilft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>\" Wer nicht zahlen kann ,  der hat Pech \"</td>\n",
       "      <td>Griechenland: Exrichter Leandros Rakintzis sol...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Factiva-20200827-1049 (1).txt</td>\n",
       "      <td>wer nicht zahlen kann der hat pech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>Kaum Wirkung</td>\n",
       "      <td>Sanktionen gegen Russland haben nur begrenzte ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Factiva-20200827-1049.txt</td>\n",
       "      <td>kaum wirkung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   journal  day  month  year  \\\n",
       "0  Spiegel   23      5  2015   \n",
       "1  Spiegel   12      9  2015   \n",
       "2  Spiegel   10     10  2015   \n",
       "3  Spiegel   24     10  2015   \n",
       "4  Spiegel   19     11  2015   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Hausmitteilung   \n",
       "1  Der serbische Premier Vucic über die Flüchtlin...   \n",
       "2                                       Reisen hilft   \n",
       "3          \" Wer nicht zahlen kann ,  der hat Pech \"   \n",
       "4                                       Kaum Wirkung   \n",
       "\n",
       "                                                text  sentiment  \\\n",
       "0  Sie sind etwa so hoch wie die Außenmauern des ...        0.0   \n",
       "1  Der serbische Ministerpräsident Aleksandar Vuč...        1.0   \n",
       "2  Tourismus leistet einen Beitrag zur Wirtschaft...        1.0   \n",
       "3  Griechenland: Exrichter Leandros Rakintzis sol...       -1.0   \n",
       "4  Sanktionen gegen Russland haben nur begrenzte ...       -1.0   \n",
       "\n",
       "                            file  \\\n",
       "0      Factiva-20200827-1114.txt   \n",
       "1      Factiva-20200827-1056.txt   \n",
       "2      Factiva-20200827-1050.txt   \n",
       "3  Factiva-20200827-1049 (1).txt   \n",
       "4      Factiva-20200827-1049.txt   \n",
       "\n",
       "                                         title_clean  \n",
       "0                                     hausmitteilung  \n",
       "1  der serbische premier vucic über die flüchtlin...  \n",
       "2                                       reisen hilft  \n",
       "3                 wer nicht zahlen kann der hat pech  \n",
       "4                                       kaum wirkung  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary to transform month name into month number\n",
    "name_to_number = {\n",
    "    u'Januar': '01', u'Februar': '02', u'M\\xe4rz': '03', u'April': '04', u'Mai': '05',\n",
    "    u'Juni': '06', u'Juli': '07', u'August': '08', u'September': '09', u'Oktober': '10',\n",
    "    u'November': '11', u'Dezember': '12'\n",
    "}\n",
    "\n",
    "# Transform month names into month numbers\n",
    "spiegel_factiva['month_num'] = spiegel_factiva['month'].map(name_to_number)\n",
    "\n",
    "# Create dictionary to transform single-digit day numbers\n",
    "day_transform = {u'1': '01', u'2': '02', u'3': '03', u'4': '04', u'5': '05', u'6': '06', u'7': '07', u'8': '08', u'9': '09'}\n",
    "\n",
    "# Transform single-digit day numbers into two-digit format\n",
    "spiegel_factiva['day'] = spiegel_factiva['day'].map(lambda d: day_transform.get(d, d))\n",
    "\n",
    "# Combine day, month, and year into a date string\n",
    "spiegel_factiva['date'] = spiegel_factiva.apply(lambda row: f\"{row['day']}.{row['month_num']}.{row['year']}\", axis=1)\n",
    "\n",
    "# Drop duplicated articles, keeping the first occurrence\n",
    "# We have duplicates because we mistakenly downloaded the same article twice\n",
    "spiegel_factiva = spiegel_factiva.drop_duplicates(['text', 'year', 'month', 'day'], keep='first')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "spiegel_factiva = spiegel_factiva.reset_index(drop=True)\n",
    "\n",
    "# Initialize the Normalize class with the titles from the spiegel_factiva DataFrame\n",
    "normalizer = Normalize(spiegel_factiva.title)\n",
    "\n",
    "# Apply the normalization process to the titles\n",
    "normalized_titles = normalizer.normalized()\n",
    "\n",
    "# Add the normalized titles to the spiegel_factiva DataFrame as a new column 'title_clean'\n",
    "spiegel_factiva['title_clean'] = normalized_titles\n",
    "\n",
    "# Merge with sentiment_data on title_clean and date\n",
    "data_match_factiva = pd.merge(sentiment_data, spiegel_factiva, how='inner', on=['title_clean', 'date'])\n",
    "\n",
    "# Rename the 'month_num' column to 'month'\n",
    "data_match_factiva = data_match_factiva.rename(columns={'month_num': 'month'})\n",
    "\n",
    "# Rename the 'year_y' column to 'year'\n",
    "data_match_factiva = data_match_factiva.rename(columns={'year_y': 'year'})\n",
    "\n",
    "# Convert year, month, and day to integers\n",
    "data_match_factiva['year'] = data_match_factiva['year'].astype(int)\n",
    "data_match_factiva['month'] = data_match_factiva['month'].astype(int)\n",
    "data_match_factiva['day'] = data_match_factiva['day'].astype(int)\n",
    "\n",
    "# Sort the data in chronological order\n",
    "data_match_factiva = data_match_factiva.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "data_match_factiva = data_match_factiva.reset_index(drop=True)\n",
    "\n",
    "# Rename the 'title_y' column to 'title' to reflect the title from the Factiva dataset\n",
    "data_match_factiva = data_match_factiva.rename(columns={'title_y': 'title'})\n",
    "\n",
    "# Select only the required columns\n",
    "data_match_factiva = data_match_factiva[['journal', 'day', 'month', 'year', 'title', 'text', 'sentiment', 'file', 'title_clean']]\n",
    "\n",
    "# Print the number of articles from Factiva\n",
    "num_factiva_articles = len(data_match_factiva)\n",
    "\n",
    "print(f\"Number of articles from Factiva: {num_factiva_articles}\")\n",
    "\n",
    "# Display the first few rows of the final matched dataset\n",
    "data_match_factiva.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Match Articles from LexisNexis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, our focus is on loading Spiegel articles that were downloaded from LexisNexis and matching them with their sentiment annotations. We begin by converting the RTF files into TXT format. The original RTF files are located in `MediaTenor_LexisNexis_Factiva/Spiegel_Konjunktur_LexisNexis_rtf`, and the resulting TXT files are stored in `MediaTenor_LexisNexis_Factiva/Spiegel_Konjunktur_LexisNexis_txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for Spiegel RTF and TXT directories\n",
    "spiegel_lexisnexis_rtf_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'Spiegel_Konjunktur_LexisNexis_rtf')\n",
    "spiegel_lexisnexis_txt_path = os.path.join(os.getcwd(), 'MediaTenor_LexisNexis_Factiva', 'Spiegel_Konjunktur_LexisNexis_txt_test')\n",
    "\n",
    "# Convert RTF files to TXT format for Spiegel\n",
    "convert_rtf_to_txt(spiegel_lexisnexis_rtf_path, spiegel_lexisnexis_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the RTF files were converted to TXT format, we made some adjustments. Before extracting titles from the 'Search Terms' in our TXT files, we corrected a few titles to ensure they matched those in the Media Tenor dataset. For example, \"**es** muss jetzt schnell gehen\" was corrected to \"**Es** muss jetzt schnell gehen\" to ensure accurate matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing the TXT files, we used the `extract_article_data_spiegel_lexisnexis` function to load the articles' text, along with the journal name, publication date, title, and file name, into a dictionary called a`article_data_lexisnexis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_article_data_spiegel_lexisnexis\n",
    "\n",
    "# Read and extract relevant information from TXT files in Spiegel directory.\n",
    "article_data_lexisnexis = extract_article_data_spiegel_lexisnexis.extract_article_data_spiegel_lexisnexis(spiegel_lexisnexis_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `article_data_lexisnexis` dictionary to create a DataFrame `spiegel_lexisnexis` that includes columns for the journal's name, publication date (day, month, and year), article title, text, and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>5</td>\n",
       "      <td>März</td>\n",
       "      <td>2012</td>\n",
       "      <td>Zahl der Woche</td>\n",
       "      <td>besuchten im vergangenen Jahr Deutschkurse an ...</td>\n",
       "      <td>234 587 Sprachsch_ler.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>08</td>\n",
       "      <td>Dezember</td>\n",
       "      <td>2014</td>\n",
       "      <td>37000</td>\n",
       "      <td>Fußnote. Menschen aus Eritrea haben sich in de...</td>\n",
       "      <td>37000.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>26</td>\n",
       "      <td>Mai</td>\n",
       "      <td>2014</td>\n",
       "      <td>81 Millionäre</td>\n",
       "      <td>Fußnote. aus dem nicht europäischen Ausland, f...</td>\n",
       "      <td>81 Million_re.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>30</td>\n",
       "      <td>April</td>\n",
       "      <td>2012</td>\n",
       "      <td>Abschwung in Sicht</td>\n",
       "      <td>Deutschland bekommt für seine Beschäftigungspo...</td>\n",
       "      <td>Abschwung in Sicht.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>2</td>\n",
       "      <td>Januar</td>\n",
       "      <td>2012</td>\n",
       "      <td>Arbeitgeber bestreiten Nachholbedarf</td>\n",
       "      <td>Im Jahr 2012 werden für rund 3,6 Millionen Bes...</td>\n",
       "      <td>Arbeitgeber bestreiten Nachholbedarf.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   journal day     month  year                                 title  \\\n",
       "0  Spiegel   5      März  2012                        Zahl der Woche   \n",
       "1  Spiegel  08  Dezember  2014                                37000    \n",
       "2  Spiegel  26       Mai  2014                         81 Millionäre   \n",
       "3  Spiegel  30     April  2012                    Abschwung in Sicht   \n",
       "4  Spiegel   2    Januar  2012  Arbeitgeber bestreiten Nachholbedarf   \n",
       "\n",
       "                                                text  \\\n",
       "0  besuchten im vergangenen Jahr Deutschkurse an ...   \n",
       "1  Fußnote. Menschen aus Eritrea haben sich in de...   \n",
       "2  Fußnote. aus dem nicht europäischen Ausland, f...   \n",
       "3  Deutschland bekommt für seine Beschäftigungspo...   \n",
       "4  Im Jahr 2012 werden für rund 3,6 Millionen Bes...   \n",
       "\n",
       "                                       file  \n",
       "0                 234 587 Sprachsch_ler.txt  \n",
       "1                                 37000.txt  \n",
       "2                         81 Million_re.txt  \n",
       "3                    Abschwung in Sicht.txt  \n",
       "4  Arbeitgeber bestreiten Nachholbedarf.txt  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "spiegel_lexisnexis = pd.DataFrame({\n",
    "    'journal': article_data_lexisnexis['journal'],\n",
    "    'day': article_data_lexisnexis['day'],\n",
    "    'month': article_data_lexisnexis['month'],\n",
    "    'year': article_data_lexisnexis['year'],\n",
    "    'title': article_data_lexisnexis['title'],\n",
    "    'text': article_data_lexisnexis['text'],\n",
    "    'file': article_data_lexisnexis['file']\n",
    "})\n",
    "\n",
    "spiegel_lexisnexis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the full texts of the loaded articles with their sentiment annotations from the Media Tenor dataset, we follow several key steps. First, we create a date in the same format as in the `sentiment_data` DataFrame. Next, we normalize the titles to ensure accurate matching. We also verify that there are no duplicate articles. After pre-processing, we merge the articles loaded from LexisNexis with their sentiment annotations from the Media Tenor dataset. We then sort the final DataFrame `data_match_lexisnexis` in chronological order and retain only the relevant columns. Through this process, we successfully matched 72 Spiegel articles from LexisNexis with their sentiment annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles from LexisNexis: 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>file</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bremsen Banken das Wachstum?</td>\n",
       "      <td>Die Samstagsfrage. Zu den vergleichsweise sich...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Bremsen Banken das Wachstum_.txt</td>\n",
       "      <td>bremsen banken das wachstum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>Skeptischer IWF</td>\n",
       "      <td>Wachstum. Der Internationale Währungsfonds (IW...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Skeptischer IWF.txt</td>\n",
       "      <td>skeptischer iwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>Der zerplatzte Traum</td>\n",
       "      <td>Am Vorabend der Olympischen Spiele befindet si...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Der zerplatzte Traum.txt</td>\n",
       "      <td>der zerplatzte traum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>Krieg auf den Hügeln</td>\n",
       "      <td>Einige Jahre lang war Rio das Schaufenster ein...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Krieg auf den H_geln.txt</td>\n",
       "      <td>krieg auf den hügeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>Ein Angriff auf die Demokratie</td>\n",
       "      <td>Der spanische Schriftsteller Javier Cercas übe...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Ein Angriff auf die Demokratie.txt</td>\n",
       "      <td>ein angriff auf die demokratie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    journal  day  month  year                            title  \\\n",
       "67  Spiegel   25      7  2015     Bremsen Banken das Wachstum?   \n",
       "68  Spiegel   26      9  2015                  Skeptischer IWF   \n",
       "69  Spiegel   30      7  2016             Der zerplatzte Traum   \n",
       "70  Spiegel    3      6  2017             Krieg auf den Hügeln   \n",
       "71  Spiegel   30      9  2017  Ein Angriff auf die Demokratie    \n",
       "\n",
       "                                                 text  sentiment  \\\n",
       "67  Die Samstagsfrage. Zu den vergleichsweise sich...       -1.0   \n",
       "68  Wachstum. Der Internationale Währungsfonds (IW...       -1.0   \n",
       "69  Am Vorabend der Olympischen Spiele befindet si...       -1.0   \n",
       "70  Einige Jahre lang war Rio das Schaufenster ein...       -1.0   \n",
       "71  Der spanische Schriftsteller Javier Cercas übe...       -1.0   \n",
       "\n",
       "                                  file                     title_clean  \n",
       "67    Bremsen Banken das Wachstum_.txt     bremsen banken das wachstum  \n",
       "68                 Skeptischer IWF.txt                 skeptischer iwf  \n",
       "69            Der zerplatzte Traum.txt            der zerplatzte traum  \n",
       "70            Krieg auf den H_geln.txt            krieg auf den hügeln  \n",
       "71  Ein Angriff auf die Demokratie.txt  ein angriff auf die demokratie  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform month names into month numbers\n",
    "spiegel_lexisnexis['month_num'] = spiegel_lexisnexis['month'].map(name_to_number)\n",
    "\n",
    "# Transform single-digit day numbers into two-digit format\n",
    "spiegel_lexisnexis['day'] = spiegel_lexisnexis['day'].map(lambda d: day_transform.get(d, d))\n",
    "\n",
    "# Combine day, month, and year into a date string\n",
    "spiegel_lexisnexis['date'] = spiegel_lexisnexis.apply(lambda row: f\"{row['day']}.{row['month_num']}.{row['year']}\", axis=1)\n",
    "\n",
    "# Initialize the Normalize class with the titles from the spiegel_lexisnexis DataFrame\n",
    "normalizer = Normalize(spiegel_lexisnexis.title)\n",
    "\n",
    "# Apply the normalization process to the titles\n",
    "normalized_titles = normalizer.normalized()\n",
    "\n",
    "# Add the normalized titles to the spiegel_lexisnexis DataFrame as a new column 'title_clean'\n",
    "spiegel_lexisnexis['title_clean'] = normalized_titles\n",
    "\n",
    "# Merge with sentiment_data on title_clean and date\n",
    "data_match_lexisnexis = pd.merge(sentiment_data, spiegel_lexisnexis, how='inner', on=['title_clean', 'date'])\n",
    "\n",
    "# Rename the 'month_num' column to 'month'\n",
    "data_match_lexisnexis = data_match_lexisnexis.rename(columns={'month_num': 'month'})\n",
    "\n",
    "# Rename the 'year_y' column to 'year'\n",
    "data_match_lexisnexis = data_match_lexisnexis.rename(columns={'year_y': 'year'})\n",
    "\n",
    "# Convert year, month, and day to integers\n",
    "data_match_lexisnexis['year'] = data_match_lexisnexis['year'].astype(int)\n",
    "data_match_lexisnexis['month'] = data_match_lexisnexis['month'].astype(int)\n",
    "data_match_lexisnexis['day'] = data_match_lexisnexis['day'].astype(int)\n",
    "\n",
    "# Sort the data in chronological order\n",
    "data_match_lexisnexis = data_match_lexisnexis.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "data_match_lexisnexis = data_match_lexisnexis.reset_index(drop=True)\n",
    "\n",
    "# Rename the 'title_y' column to 'title' to reflect the title from the LexisNexis dataset\n",
    "data_match_lexisnexis = data_match_lexisnexis.rename(columns={'title_y': 'title'})\n",
    "\n",
    "# Select only the required columns\n",
    "data_match_lexisnexis = data_match_lexisnexis[['journal', 'day', 'month', 'year', 'title', 'text', 'sentiment', 'file', 'title_clean']]\n",
    "\n",
    "# Print the number of articles from LexisNexis\n",
    "num_lexisnexis_articles = len(data_match_lexisnexis)\n",
    "\n",
    "print(f\"Number of articles from LexisNexis: {num_lexisnexis_articles}\")\n",
    "\n",
    "# Display the last few rows of the final matched dataset\n",
    "data_match_lexisnexis.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the final step, we consolidate all Spiegel articles, including those that were scraped and those downloaded from Factiva and LexisNexis, into a single DataFrame called `spiegel_all`. This combined DataFrame is then saved as a CSV file named `spiegel.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles: 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>file</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>Schockwellen aus Fernost</td>\n",
       "      <td>Schockwellen aus Fernost. Die Katastrophe in J...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>schockwellen aus fernost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>Kalter Krieg</td>\n",
       "      <td>Kalter Krieg. Sanfte Umschuldung oder Weiter-s...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>kalter krieg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>Wieder am Abgrund</td>\n",
       "      <td>Wieder am Abgrund. Die Griechen brauchen noch ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>wieder am abgrund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>Die Nicht-Regierung</td>\n",
       "      <td>Die Nicht-Regierung. Angela Merkel bekommt ihr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>die nicht regierung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiegel</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>„Große Defizite“</td>\n",
       "      <td>„Große Defizite“. Bundesfinanzminister Wolfgan...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>spiegel_2011_2015.csv</td>\n",
       "      <td>große defizite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   journal  day  month  year                     title  \\\n",
       "0  Spiegel   21      3  2011  Schockwellen aus Fernost   \n",
       "1  Spiegel   30      5  2011              Kalter Krieg   \n",
       "2  Spiegel    6      6  2011         Wieder am Abgrund   \n",
       "3  Spiegel   27      6  2011       Die Nicht-Regierung   \n",
       "4  Spiegel    4      7  2011          „Große Defizite“   \n",
       "\n",
       "                                                text  sentiment  \\\n",
       "0  Schockwellen aus Fernost. Die Katastrophe in J...       -1.0   \n",
       "1  Kalter Krieg. Sanfte Umschuldung oder Weiter-s...       -1.0   \n",
       "2  Wieder am Abgrund. Die Griechen brauchen noch ...       -1.0   \n",
       "3  Die Nicht-Regierung. Angela Merkel bekommt ihr...        1.0   \n",
       "4  „Große Defizite“. Bundesfinanzminister Wolfgan...       -1.0   \n",
       "\n",
       "                    file               title_clean  \n",
       "0  spiegel_2011_2015.csv  schockwellen aus fernost  \n",
       "1  spiegel_2011_2015.csv              kalter krieg  \n",
       "2  spiegel_2011_2015.csv         wieder am abgrund  \n",
       "3  spiegel_2011_2015.csv       die nicht regierung  \n",
       "4  spiegel_2011_2015.csv            große defizite  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all articles from scraped, Factiva, and LexisNexis datasets into a single DataFrame\n",
    "spiegel_all = pd.concat([data_match_scraped, data_match_factiva, data_match_lexisnexis], sort=False)\n",
    "\n",
    "# Reset the index of the combined DataFrame\n",
    "spiegel_all = spiegel_all.reset_index(drop=True)\n",
    "\n",
    "# Print the total number of articles in the combined DataFrame\n",
    "total_articles = len(spiegel_all)\n",
    "print(f\"Total number of articles: {total_articles}\")\n",
    "\n",
    "# Display the first few rows of the combined DataFrame to verify the merge\n",
    "spiegel_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the combined DataFrame in chronological order\n",
    "spiegel_all = spiegel_all.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "spiegel_all = spiegel_all.reset_index(drop=True)\n",
    "\n",
    "# Drop the 'title_clean' column as it is no longer needed\n",
    "spiegel_all = spiegel_all.drop(columns=['title_clean'])\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "spiegel_all.to_csv('spiegel.csv', encoding='utf-8-sig', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
